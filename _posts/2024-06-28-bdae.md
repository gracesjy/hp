---
title: Big Data Analysis Enabler
author: Raymond
date: 2024-06-28
category: Jekyll
layout: post
---

## <span style="color:#034299">About BDAE&#8482;(Big Data Analysis Enabler&#8482;, AI Enabler) for Oracle Database&#8482;</span>

***Big Data Analysis Enabler(BDAE)*** enables parallel processing of Python and R without data movement based on Oracle In-Database.
Because it implements the ***Oracle Data Cartridge Interface***, it is not limited to a specific schema and supports ***Dynamic SQL***.<br>
(contact : gracesjy@naver.com)<br>

***This*** is built on Oracle In-Database technology and has platform features that enable ***Oracle Database&#8482;***
to be used not only as a simple storage for general AI tasks, but also as a non-stop operating environment
without the overhead of data movement during learning and inference.<br>

<img src="../assets/Oracle_In_Database.png" width="50%" height="50%">

Below Image shows the operating location of BDAE&#8482; in the form of Oracle In-Database.
Parallel distributed processing is a feature of Oracle In-Database, and analysts do not need to consider it in their modules, which increases the reusability of logic.
In addition, the fact that it can be integrated with various analysis engines can be seen as an advantage of BDAE&#8482;. <br><br>

<img src="../assets/BDAE_SW_Arch01.png" width="50%" height="50%">

This can improve performance by reducing the number of DB calls while writing backend programs in Python and R.<br>
***Note)*** <br>
1.    ***BDAE&#8482;*** was developed with inspiration from ***Oracle R Enterprise&#8482;*** and was created solely using Oracle manuals.<br>
      However, it took a lot of time to develop through trial and error due to the lack of examples.<br>
      This is a work that I thought of and created on my own.<br>
2.    ***BDAE&#8482;*** enables your Python/R modules to run with parallelism like ***Oracle R Enterprise&#8482;***. <br>
3.    But, ***BDAE&#8482;*** has no alogithm unlike **Oracle R Enterprise&#8482;**, just Tool for AI (Machine Learning). <br>
      Algorithms are not included because they are constantly evolving and changing. This is also because analysts can do better. <br>
4.    Embedded Python/R execution provides some of the most significant advantages of using ***BDAE&#8482;***. Using embedded Python/R execution, <br>
      you can store and run Python/R scripts in the database through either an Python/R interface or a SQL interface or both. <br>
      You can use the results of Python/R scripts in SQL-enabled tools for structured data, Python/R objects, and images.

## <span style="color:#034299">How To run (3 Steps to Run !)</span>
1. Register your Python/R model in the designated Oracle Database&#8482;'s table or save file in PYTHONPATH directory.
2. Register the SQL to bind source data and your model.
3. Run the SQL and get the results.  you can get results any tools capable of connecting Oracle Database&#8482;.
***Note*** Using BDAE&#8482; Web, you can simply and easily register Python/R and SQLs with Editor. (just copy & paste from Jupyter Notebook or Something)

### Step-1) Make Your Python module (ML/DL/ ...)

You must make entry function of module, for example describe().
others are helper functions. 

```
import numpy as np
import os
import matplotlib as mpl
import matplotlib.pyplot as plt
import pandas as pd
import tempfile
import base64
from pandas.plotting import scatter_matrix

def make_output(df, key, data):
   df[key] = data
   return df

def image_to_html():
   tmp_file_name = tempfile.NamedTemporaryFile().name + '.png'
   plt.savefig(tmp_file_name)
   image = open(tmp_file_name, 'rb')
   image_read = image.read()
   image_64_encode = base64.b64encode(image_read)
   uri = '<img src="data:img/png;base64,' + image_64_encode.decode() + '">'
   html_str = "<html><body>" + uri + "</body></html>"
   if os.path.exists(tmp_file_name):
      os.remove(tmp_file_name)
   return html_str

def describe(housing):
   # 0) Prepare Output
   tupleStart = {'subject': [ 'General ML' ] }
   pdf = pd.DataFrame(tupleStart)

   # 1) Historam
   housing.hist(bins=50, figsize=(20,15))
   a = image_to_html()
   pdf = make_output(pdf, 'Histogram', a)

   # 2) Scatter Plot
   housing.plot(kind="scatter", x="LONGITUDE", y="LATITUDE", alpha=0.4,
             s=housing["POPULATION"]/100, label="POPULATION", figsize=(10,7),
             c="MEDIAN_HOUSE_VALUE", cmap=plt.get_cmap("jet"), colorbar=True,
             sharex=False)
   plt.legend()
   a = image_to_html()
   pdf = make_output(pdf, 'ScatterPlot', a)

   # 3) Scatter Matrix
   attributes = ["MEDIAN_HOUSE_VALUE", "MEDIAN_INCOME", "TOTAL_ROOMS",
              "HOUSING_MEDIAN_AGE"]
   scatter_matrix(housing[attributes], figsize=(12, 8))
   a = image_to_html()
   pdf = make_output(pdf, 'ScatterMatrix', a)
   
   return pdf
```

### Step-2) Make Your SQL to run

The input (Oracle Database&#8482;'s Table or View or Queries) is delivered 
pandas DataFrame format to your python entry point function,
and You must make the results into pandas DataFrame format !,
because of Oracle Database&#8482; Query Results(RDBMS).

```
SELECT * 
      FROM table(apTableEval(
         	cursor(SELECT * FROM CAL_HOUSING),  -- Input Data (Driving Table)
         	NULL,  -- Secondary Input Data
            'SELECT CAST(''A'' AS VARCHAR2(40)) SUBJECT,  -- Output Format
                  TO_CLOB(NULL) H1, TO_CLOB(NULL) H2, TO_CLOB(NULL) H3 
             FROM DUAL',
           'CAL_HOUSING_EDM:describe'))  -- Python Module for calling
```

### Step-3) Run above SQL and get Results
Like General SQL Queries' results, BDAE&#8482;'s results are the same.
(Any Applications you can develope using SQLs)
<br>
<img src="../assets/ResultsEDM.png" width="80%" height="80%">



---------------------------------------
## <span style="color:#034299">Installation</span>

Oracle Database&#8482; is provided as Docker, and installation of Python and R with Anaconda has also become very convenient.<br>
Therefore, BDAE&#8482; installation is very quick and can be installed within 5 minutes.<br><br>
This Docker can be provided in Docker tar file format and can be imported to your computer using following method.<br><br>
> docker load -i bdae_oracle.tar

<img src="../assets/BDAE_DOCKER.png" width="80%" height="80%">

Please send me the mail if you want to test. (gracesjy@naver.com)<br>

---------------------------------------
## <span style="color:#034299">Manual</span>
[Big Data Analysis Enabler&#8482; Summary(English)](https://github.com/gracesjy/hp/blob/master/assets/BDAE_Manual.pdf)

## More Information
[Big Data Analysis Enabler&#8482; GitHub](https://github.com/gracesjy/bdae)

## Example #1
License Plate or Aquarium

> Python Source (YOLOv8:train saved into BDAE PYSCRIPT Table)
```
from ultralytics import YOLO
import pandas as pd
import numpy as np
import os
os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'
os.environ['PYTHONIOENCODING']='UTF-8'
import logging, logging.handlers
import sys
import base64
from os import listdir
from os.path import isfile, join
from StreamToLogger import StreamToLogger
import logging, logging.handlers

# comment
file_loc = []

def yolo_callback(x):
    print("yolo callback called !")
    file_loc.append(str(x))


def image_to_html(filename):
    image = open(filename, 'rb')
    image_read = image.read()
    image_64_encode = base64.b64encode(image_read)
    uri = '<img src="data:img/png;base64,' + image_64_encode.decode() + '">'
    html_str = "<html><body>" + uri + "</body></html>"
    return html_str

def train(df_args):
    logger = logging.getLogger('AquaModelByYOLOv8:train')
    logger.setLevel(logging.DEBUG)
    
    socketHandler = logging.handlers.SocketHandler('localhost',
                    logging.handlers.DEFAULT_TCP_LOGGING_PORT)
    
    logger.addHandler(socketHandler)
    
    sys.stdout = StreamToLogger(logger,logging.INFO)
    sys.stderr = StreamToLogger(logger,logging.ERROR)
    
    print("----- Aqua Object Detection by YOLOv8 start ------")
    model = YOLO("yolov8n.pt")
    # result = model.train(data='/home/oracle/DeepLearning/Aquarium_Combined.v2-raw-1024.yolov8/data.yaml', epochs=10,patience=30,batch=16,imgsz=416)
    result = model.train(data=df_args['PATH'], epochs=10,patience=30,batch=16,imgsz=416)
    result_dir = str(result.save_dir)
    result_chart_data = []
    result_chart_name = []
    
    onlyfiles = [f for f in listdir(result_dir) if isfile(join(result_dir, f))]
    print(onlyfiles)

    for i in range(len(onlyfiles)):
        if onlyfiles[i].lower().endswith(('.png', '.jpg', '.jpeg')) == True:
            result_chart_name.append(onlyfiles[i])
            print('before open file : ' + result_dir + '/' + onlyfiles[i])
            result_chart_data.append(image_to_html(result_dir + '/' + onlyfiles[i]))
        
    #result.confusion_matrix.plot(normalize=True, save_dir='/tmp', names=(list(model.names.values())), on_plot=yolo_callback)
    #cm_chart_clob = image_to_html(file_loc[0])
    
    dictData = {'Chart Name': result_chart_name, 'Chart': result_chart_data }
    print("----- Aqua Object Detection by YOLOv8 end ------")
    pdf = pd.DataFrame(dictData)
    return pdf
```

BDAE SQL
```
SELECT *
FROM table(apEval(
   cursor(SELECT '/home/oracle/DeepLearning/Aquarium_Combined.v2-raw-1024.yolov8/data.yaml' PATH FROM dual),
   'SELECT CAST(NULL AS VARCHAR2(400)) CHART_NAME, TO_CLOB(NULL) CHART_DATA FROM dual',
   'YOLOv8:train'))
```
